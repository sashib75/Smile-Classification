{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLrMDvbhe2WD"
      },
      "source": [
        "# **SMILE CLASSIFICATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeZrUHLge7ri"
      },
      "source": [
        "# **OVERVIEW**\n",
        "\n",
        "This notebook demonstrates classifying images of different faces into **three categories**. They are as follows:\n",
        "\n",
        "1.   **NOT smile** : The face doesnâ€™t have a smile.\n",
        "2.   **POSITIVE smile** : The face has a real smile.\n",
        "3.   **NEGATIVE smile** : The face has a fake smile.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PaNjpaDFaSo"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries and modules\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import gc\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.efficientnet import EfficientNetB7\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crwQBfmnfEQb"
      },
      "source": [
        "The images folder in the data is in .zip format. We use [zipfile](https://docs.python.org/3/library/zipfile.html) library to extract images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI1xBscIdYd3"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/Copy of happy_images.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/drive/MyDrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PLf3FQEfJqy"
      },
      "source": [
        "We use [pathlib](https://docs.python.org/3/library/pathlib.html) module for file handling. This provides an object API for working with files and directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIV19ZCjda91"
      },
      "outputs": [],
      "source": [
        "image_folder=Path(\"/content/drive/MyDrive/happy_images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-kelUqbfTBR"
      },
      "source": [
        "Let's visualize some of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydmeC9SAddsi"
      },
      "outputs": [],
      "source": [
        "#Creating axes\n",
        "fig,ax=plt.subplots(7,7,figsize=(20,20))\n",
        "ax=ax.ravel()\n",
        "i=0\n",
        "\n",
        "#iterdir allows us to iterate the files in the directory\n",
        "for entries in image_folder.iterdir():\n",
        "  image=Image.open(str(entries))\n",
        "  ax[i].imshow(image)\n",
        "  if i==48:\n",
        "    break\n",
        "  i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcuf69nudgo2"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv(\"/content/drive/MyDrive/Copy of train.csv\",header=None)\n",
        "test=pd.read_csv(\"/content/drive/MyDrive/Copy of test.csv\",header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZWq7x3jdjMH"
      },
      "outputs": [],
      "source": [
        "train[1].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0NS-BJ5dleC"
      },
      "outputs": [],
      "source": [
        "# Check for class imbalance\n",
        "sns.countplot(x=train[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyPfjEQDfYl9"
      },
      "source": [
        "From the above graph, it is evident that there is **class imbalance** in our data. To avoid this problem, let's perform **oversampling** of minority classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSvTOj-ufciA"
      },
      "source": [
        "# **BALANCING CLASSES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm9v8FHrdn-3"
      },
      "outputs": [],
      "source": [
        "def balance_classes(df,split_ratio):\n",
        "    \"\"\"This function oversamples the minority classes to balance the data\"\"\"\n",
        "\n",
        "    # We are splitting the data before oversmapling to avoid data leakage problem.\n",
        "    train_df=df.iloc[:int(len(df)*(1-split_ratio)),:]\n",
        "    test_df=df.iloc[int(len(df)*(1-split_ratio)):,:]\n",
        "\n",
        "    # Getting the number of samples to required to balance the classes \n",
        "    extra_pos_smile=sum(train_df[\"label\"]==\"NOT smile\")-sum(train_df[\"label\"]==\"positive smile\")\n",
        "    extra_neg_smile=sum(train_df[\"label\"]==\"NOT smile\")-sum(train_df[\"label\"]==\"negative smile\")\n",
        "    \n",
        "    # Sampling the required number of rows from train dataframe\n",
        "    pos_smile_samples=train_df[train_df[\"label\"]==\"positive smile\"].sample(extra_pos_smile,replace=True,random_state=0)\n",
        "    neg_smile_samples=train_df[train_df[\"label\"]==\"negative smile\"].sample(extra_neg_smile,replace=True,random_state=0)\n",
        "    \n",
        "    # Concatenating the sampled data\n",
        "    train_df=pd.concat([train_df,pos_smile_samples,neg_smile_samples],ignore_index=True)\n",
        "    \n",
        "    # Shuffling the dataframe\n",
        "    train_df=train_df.sample(frac=1)\n",
        "    \n",
        "    # Resetting the indices of the train and test dataframes\n",
        "    train_df.reset_index(inplace=True,drop=True)\n",
        "    test_df.reset_index(inplace=True,drop=True)\n",
        "    \n",
        "    return train_df,test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp4rj3O8du8W"
      },
      "source": [
        "Now, Let's preprocess the images to improve the **quality** so that we can analyse it in a better way and to suppress **undesired distortions** and enhance some features which are necessary for our classification."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMAGE PROCESSING**"
      ],
      "metadata": {
        "id": "IJaA_0ZELjCf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxTodyjafjGQ"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(path, image_width, image_height):\n",
        "\n",
        "    image=cv2.imread(path)\n",
        "\n",
        "    # Converting the image from RGB band to BGR\n",
        "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Resizing image to a fixed image_width and image_height\n",
        "    image=cv2.resize(image,(image_width,image_height))\n",
        "    \n",
        "    # Applying clahe equalization to each channel to improve contrast and brightness of the image\n",
        "    clahe=cv2.createCLAHE(clipLimit = 4,tileGridSize=(2,2))\n",
        "    for channel in range(3):\n",
        "      image[:, :, channel] = clahe.apply(image[:, :, channel])\n",
        "\n",
        "    image = cv2.fastNlMeansDenoisingColored(image, None, 10,10,7,21)\n",
        "    \n",
        "    # Applying dilation to whiten teeth pixels and remove black tint for better feature extraction\n",
        "    kernel = np.ones((3,3),np.uint8)\n",
        "    image = cv2.dilate(image,kernel,iterations = 1)\n",
        "\n",
        "    # Sharpen the image to remove blur and highlight the edges of key features\n",
        "    sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "    image = cv2.filter2D(image, -1, sharpen_kernel)\n",
        "    \n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQFOXGUjfmXw"
      },
      "source": [
        "Finally, get the image arrays from the happy_images directory"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INPUT PREPROCESSING**"
      ],
      "metadata": {
        "id": "U7OCXGbyL0DE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKAYVFBAfj81"
      },
      "outputs": [],
      "source": [
        "def input_preprocess(dataframe,image_width,image_height):\n",
        "    \"\"\"This function converts the images into arrays\"\"\"\n",
        "    \n",
        "    df=dataframe.copy()\n",
        "\n",
        "    #Renaming the labels of dataframe\n",
        "    df.columns=[\"id\",\"label\"]\n",
        "    \n",
        "    # Balancing classes\n",
        "    train_df,test_df=balance_classes(df,split_ratio=0.15)\n",
        "    \n",
        "    # Converting train dataframe into arrays\n",
        "    X_train=[];i=0;y_train=[]\n",
        "    for filename in train_df[\"id\"].values:\n",
        "        path = \"/content/drive/MyDrive/happy_images/\"+filename+\".jpg\"\n",
        "        image = preprocess_image(path, image_width, image_height)\n",
        "        X_train.append(image)\n",
        "        y_train.append(train_df[\"label\"][i])\n",
        "\n",
        "        i+=1\n",
        "\n",
        "        # Check\n",
        "        if i%100==0:\n",
        "          print(i,\"train images completed\")\n",
        "    \n",
        "    # Converting test dataframe into arrays\n",
        "    X_test=[];i=0;y_test=[]\n",
        "    for filename in test_df[\"id\"].values:\n",
        "        path=\"/content/drive/MyDrive/happy_images/\"+filename+\".jpg\"\n",
        "        image = preprocess_image(path, image_width, image_height)\n",
        "        X_test.append(image)\n",
        "        y_test.append(test_df[\"label\"][i])\n",
        "        \n",
        "        i+=1\n",
        "\n",
        "        if i%100==0:\n",
        "          print(i,\"test images completed\")\n",
        "    \n",
        "    X_train=np.array(X_train)\n",
        "    X_test=np.array(X_test)\n",
        "    \n",
        "    # One Hot encoding of labels\n",
        "    y_train=pd.get_dummies(y_train).values\n",
        "    y_test=pd.get_dummies(y_test).values  \n",
        "    \n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9hS-IIkfrpJ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = input_preprocess(train, 150,150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMxllu5_8ybH"
      },
      "outputs": [],
      "source": [
        "# Save the files\n",
        "np.save(\"/content/drive/MyDrive/X_train.npy\", X_train)\n",
        "np.save(\"/content/drive/MyDrive/X_test.npy\", X_test)\n",
        "np.save(\"/content/drive/MyDrive/y_train.npy\", y_train)\n",
        "np.save(\"/content/drive/MyDrive/y_test.npy\", y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqmR_QRyEOmv"
      },
      "outputs": [],
      "source": [
        "X_train = np.load(\"/content/drive/MyDrive/X_train.npy\")\n",
        "X_test = np.load(\"/content/drive/MyDrive/X_test.npy\")\n",
        "y_train = np.load(\"/content/drive/MyDrive/y_train.npy\")\n",
        "y_test = np.load(\"/content/drive/MyDrive/y_test.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shapes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "F3oCb4Zpe-FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREPROCESS TEST DATA**"
      ],
      "metadata": {
        "id": "wmoqXW9WKFFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_test(dataframe, image_width, image_height):\n",
        "    df=dataframe.copy()\n",
        "\n",
        "    #Renaming the labels of dataframe\n",
        "    df.columns=[\"id\",\"label\"]\n",
        "    \n",
        "    # Converting train dataframe into arrays\n",
        "    test_X=[];i=0;test_y=[]\n",
        "    for filename in df[\"id\"].values:\n",
        "        path = \"/content/drive/MyDrive/happy_images/\"+filename+\".jpg\"\n",
        "        image = preprocess_image(path, image_width, image_height)\n",
        "        test_X.append(image)\n",
        "        test_y.append(df[\"label\"][i])\n",
        "\n",
        "        i+=1\n",
        "\n",
        "        # Check \n",
        "        if i%100==0:\n",
        "          print(i, \"samples done\")\n",
        "\n",
        "    test_X = np.array(test_X)\n",
        "    test_y = pd.get_dummies(test_y).values\n",
        "\n",
        "    return test_X, test_y"
      ],
      "metadata": {
        "id": "Y9x5PL4zJrRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_X, test_y = preprocess_test(test, 150,150)\n",
        "test_X.shape, test_y.shape"
      ],
      "metadata": {
        "id": "zA0f3yvZJvET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/test_X.npy\", test_X)\n",
        "np.save(\"/content/drive/MyDrive/test_y.npy\", test_y)"
      ],
      "metadata": {
        "id": "3CvXfEgKJypM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_X = np.load(\"/content/drive/MyDrive/test_X.npy\")\n",
        "test_y = np.load(\"/content/drive/MyDrive/test_y.npy\")"
      ],
      "metadata": {
        "id": "PgJbr7u8J1y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL** **DEVELOPMENT**"
      ],
      "metadata": {
        "id": "136fiZ11KJZc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1woPuRkBf1DH"
      },
      "outputs": [],
      "source": [
        "def build_model(pretrained_net, input_shape, classes):\n",
        "\n",
        "    if pretrained_net==\"Efficient_net\":\n",
        "      base_model = EfficientNetB7(include_top=False, weights=\"imagenet\", input_shape=input_shape,classes=classes)\n",
        "\n",
        "    elif pretrained_net==\"vgg19\":\n",
        "      base_model = VGG19(include_top=False, weights=\"imagenet\", input_shape=input_shape,classes=classes)\n",
        "\n",
        "    elif pretrained_net == \"resnet\":\n",
        "      base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=input_shape,classes=classes)\n",
        "\n",
        "    flatten_layer=Flatten()\n",
        "    dense_layer1=Dense(128,activation=\"relu\")\n",
        "    dropout_layer=Dropout(0.2)\n",
        "    dense_layer2=Dense(64,activation=\"relu\")\n",
        "    prediction_layer=Dense(3,activation=\"softmax\")\n",
        "    \n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        flatten_layer,\n",
        "        dense_layer1,\n",
        "        dropout_layer,\n",
        "        dense_layer2,\n",
        "        prediction_layer])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ResNet50**"
      ],
      "metadata": {
        "id": "WaibK9MeKaJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI9tC3lzf426"
      },
      "outputs": [],
      "source": [
        "from keras.applications.resnet import preprocess_input\n",
        "\n",
        "adam=keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "\n",
        "resnet_model = build_model(pretrained_net = \"resnet\", input_shape=X_train[0].shape, classes=y_train.shape[1])\n",
        "\n",
        "resnet_model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "X_train_resnet = preprocess_input(X_train)\n",
        "X_test_resnet = preprocess_input(X_test)\n",
        "\n",
        "resnet_history= resnet_model.fit(X_train_resnet, y_train, batch_size=32, \n",
        "                                 epochs=10, validation_data=(X_test_resnet,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEb8EY9hkddK"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "resnet_model.save(\"/content/drive/MyDrive/resnet.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the accuracy and training plots"
      ],
      "metadata": {
        "id": "90U6MQNeLUqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjkLKB1Hj57D"
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots(1,2,figsize=(15,5))\n",
        "sns.set()\n",
        "\n",
        "loss_train = resnet_history.history['loss']\n",
        "loss_val = resnet_history.history['val_loss']\n",
        "epochs = range(1,11)\n",
        "ax[0].plot(epochs, loss_train, 'r', label='Training loss')\n",
        "ax[0].plot(epochs, loss_val, 'b', label='validation loss')\n",
        "ax[0].set_title('Resnet model Training and validation loss')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "loss_train = resnet_history.history['accuracy']\n",
        "loss_val = resnet_history.history['val_accuracy']\n",
        "epochs = range(1,11)\n",
        "ax[1].plot(epochs, loss_train, 'r', label='Training accuracy')\n",
        "ax[1].plot(epochs, loss_val, 'b', label='validation accuracy')\n",
        "ax[1].set_title('Resnet model Training and Validation accuracy')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dSmQJzGPfMp"
      },
      "outputs": [],
      "source": [
        "# Test the ResNet model\n",
        "resnet_model.evaluate(test_X, test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VGG 19**"
      ],
      "metadata": {
        "id": "wzF5Aly8Kitb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCYqAqnMTrHV"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "adam=keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "\n",
        "vgg_model = build_model(pretrained_net = \"vgg19\", input_shape=X_train[0].shape, classes=y_train.shape[1])\n",
        "\n",
        "vgg_model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "X_train_vgg = preprocess_input(X_train)\n",
        "X_test_vgg = preprocess_input(X_test)\n",
        "\n",
        "vgg_history= vgg_model.fit(X_train_vgg, y_train, batch_size=32, \n",
        "                                 epochs=10, validation_data=(X_test_vgg,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJgSiL38WGyb"
      },
      "outputs": [],
      "source": [
        "vgg_model.save(\"/content/drive/MyDrive/vgg19.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv7xO3adhXcd"
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots(1,2,figsize=(15,5))\n",
        "sns.set()\n",
        "\n",
        "loss_train = vgg_history.history['loss']\n",
        "loss_val = vgg_history.history['val_loss']\n",
        "epochs = range(1,11)\n",
        "ax[0].plot(epochs, loss_train, 'r', label='Training loss')\n",
        "ax[0].plot(epochs, loss_val, 'b', label='validation loss')\n",
        "ax[0].set_title('VGG model Training and validation loss')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "loss_train = vgg_history.history['accuracy']\n",
        "loss_val = vgg_history.history['val_accuracy']\n",
        "epochs = range(1,11)\n",
        "ax[1].plot(epochs, loss_train, 'r', label='Training accuracy')\n",
        "ax[1].plot(epochs, loss_val, 'b', label='validation accuracy')\n",
        "ax[1].set_title('VGG model Training and Validation accuracy')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9CHSQLGh7cr"
      },
      "outputs": [],
      "source": [
        "vgg_model.evaluate(test_X, test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EfficientNet B7**"
      ],
      "metadata": {
        "id": "lNWUYnEBKm0J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHIJim3fjLdY"
      },
      "outputs": [],
      "source": [
        "from keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "adam=keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "\n",
        "efficientnet_model = build_model(pretrained_net = \"Efficient_net\", input_shape=X_train[0].shape, classes=y_train.shape[1])\n",
        "\n",
        "efficientnet_model.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "X_train_efficientnet = preprocess_input(X_train)\n",
        "X_test_efficientnet = preprocess_input(X_test)\n",
        "\n",
        "efficientnet_history= efficientnet_model.fit(X_train_efficientnet, y_train, batch_size=32, \n",
        "                                 epochs=10, validation_data=(X_test_efficientnet,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN1Yy7Q8oa65"
      },
      "outputs": [],
      "source": [
        "efficientnet_model.save(\"/content/drive/MyDrive/Efficient_Net.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezACTExLohqr"
      },
      "outputs": [],
      "source": [
        "fig,ax=plt.subplots(1,2,figsize=(15,5))\n",
        "sns.set()\n",
        "\n",
        "loss_train = efficientnet_history.history['loss']\n",
        "loss_val = efficientnet_history.history['val_loss']\n",
        "epochs = range(1,11)\n",
        "ax[0].plot(epochs, loss_train, 'r', label='Training loss')\n",
        "ax[0].plot(epochs, loss_val, 'b', label='validation loss')\n",
        "ax[0].set_title('Efficient-Net model Training and validation loss')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "loss_train = efficientnet_history.history['accuracy']\n",
        "loss_val = efficientnet_history.history['val_accuracy']\n",
        "epochs = range(1,11)\n",
        "ax[1].plot(epochs, loss_train, 'r', label='Training accuracy')\n",
        "ax[1].plot(epochs, loss_val, 'b', label='validation accuracy')\n",
        "ax[1].set_title('Efficient-Net model Training and Validation accuracy')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksmaPT_eo1fa"
      },
      "outputs": [],
      "source": [
        "efficientnet_model.evaluate(test_X, test_y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}